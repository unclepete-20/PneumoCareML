{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1SMwqhRMnA8Ip6jwb_tkUgQrRvzQz7UZ_",
      "authorship_tag": "ABX9TyM8a93ZvwmZmX6AT7YBLdKD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unclepete-20/PneumoCareML/blob/main/PneumoCareML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**PneumoCareML**\n",
        "\n",
        "Welcome to this Jupyter Notebook implementation guide, where we will explore the classification of pneumonia X-rays using Convolutional Neural Networks (CNNs). Pneumonia is a common and potentially life-threatening respiratory infection that affects millions of people worldwide, and the early and accurate diagnosis of pneumonia plays a vital role in improving patient outcomes.\n",
        "\n",
        "Understanding Pneumonia:\n",
        "Pneumonia is an inflammatory condition affecting the lungs, primarily caused by infection. It can be caused by various pathogens such as bacteria, viruses, fungi, or parasites, leading to the inflammation and consolidation of lung tissue. Pneumonia can range from mild to severe, with symptoms including cough, fever, difficulty breathing, and chest pain. Severe cases of pneumonia can be particularly dangerous, especially among vulnerable populations.\n",
        "\n",
        "Most Affected Population:\n",
        "Pneumonia can affect individuals of all ages, but certain populations are more susceptible to severe infections. Infants and young children, elderly individuals, and people with compromised immune systems are particularly vulnerable. In developing countries, where access to healthcare and vaccination rates may be lower, pneumonia remains a significant cause of illness and mortality among children.\n",
        "\n",
        "Global Statistics:\n",
        "Pneumonia is a leading cause of morbidity and mortality worldwide. Let's explore some statistics that highlight the impact of pneumonia on a global scale:\n",
        "\n",
        "According to the World Health Organization (WHO), pneumonia is responsible for approximately 15% of all deaths in children under the age of 5.\n",
        "Pneumonia claims the lives of more than 800,000 children under the age of 5 every year, accounting for around 2,200 deaths per day.\n",
        "In 2019, an estimated 2.5 million deaths occurred due to pneumonia among all age groups.\n",
        "Low- and middle-income countries bear a significant burden, accounting for approximately 99% of all pneumonia-related child deaths.\n",
        "Importance of X-ray Classification:\n",
        "Medical imaging, such as X-rays, plays a crucial role in diagnosing pneumonia. Radiologists often rely on X-ray images to identify patterns and abnormalities indicative of pneumonia in the lungs. However, manual interpretation of X-rays can be time-consuming and prone to human error. The integration of CNNs can assist in automating the classification process, providing efficient and accurate diagnoses.\n",
        "\n",
        "In this Jupyter Notebook, we will leverage the power of deep learning and CNNs to develop a pneumonia X-ray classification model. By training the model on a diverse dataset of X-ray images, we aim to create a system that can assist healthcare professionals in diagnosing pneumonia more effectively. Through this implementation, we hope to contribute to the ongoing efforts to improve pneumonia diagnosis and reduce the burden of this respiratory infection worldwide.\n",
        "\n",
        "Let's proceed with the notebook to explore the dataset, build the CNN model, train it on X-ray images, and evaluate its performance in classifying pneumonia accurately."
      ],
      "metadata": {
        "id": "YOb53j-DVM9a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sW1p1wTfUXE1"
      },
      "outputs": [],
      "source": [
        "# Imports neccesary to work on the project\n",
        "import re\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 - Exploratory data analysis"
      ],
      "metadata": {
        "id": "CfK3bW0vWOwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We begin the process of unifying the images in their corresponding category.\n",
        "normal_train_images = glob.glob('/content/drive/MyDrive/chest_xray/train/NORMAL/*.jpeg')\n",
        "pneumonia_train_images = glob.glob('/content/drive/MyDrive/chest_xray/train/PNEUMONIA/*.jpeg')\n",
        "\n",
        "normal_test_images = glob.glob('/content/drive/MyDrive/chest_xray/test/NORMAL/*.jpeg')\n",
        "pneumonia_test_images = glob.glob('/content/drive/MyDrive/chest_xray/test/PNEUMONIA/*.jpeg')"
      ],
      "metadata": {
        "id": "DXQ77K4ArW1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of NORMAL images: {len(normal_train_images)}\")\n",
        "print(f\"Number of PNEUMONIA images: {len(pneumonia_train_images)}\")"
      ],
      "metadata": {
        "id": "cfKgbbw4xAba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Labels are assigned to the images, e.g. 0 for NORMAL and 1 for PNEUMONIA.\n",
        "normal_train_labels = [0] * len(normal_train_images)\n",
        "pneumonia_train_labels = [1] * len(pneumonia_train_images)\n",
        "\n",
        "normal_test_labels = [0] * len(normal_test_images)\n",
        "pneumonia_test_labels = [1] * len(pneumonia_test_images)"
      ],
      "metadata": {
        "id": "J8QsjyvCvpu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The images and labels from the NORMAL and PNEUMONIA folders are now combined into a single dataset.\n",
        "train_images = normal_train_images + pneumonia_train_images\n",
        "train_labels = normal_train_labels + pneumonia_train_labels\n",
        "\n",
        "test_images = normal_test_images + pneumonia_test_images\n",
        "test_labels = normal_test_labels + pneumonia_test_labels"
      ],
      "metadata": {
        "id": "26Qdgzw2xj2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The data set is shuffled to ensure a good distribution of the images.\n",
        "train_indices = np.arange(len(train_images))\n",
        "np.random.shuffle(train_indices)\n",
        "train_images = [train_images[i] for i in train_indices]\n",
        "train_labels = [train_labels[i] for i in train_indices]\n",
        "\n",
        "test_indices = np.arange(len(test_images))\n",
        "np.random.shuffle(test_indices)\n",
        "test_images = [test_images[i] for i in test_indices]\n",
        "test_labels = [test_labels[i] for i in test_indices]"
      ],
      "metadata": {
        "id": "THOINzCZx-wA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Both cases are shown in order to observe the differences clearly\n",
        "train_n = '/content/drive/MyDrive/chest_xray/train/NORMAL/'\n",
        "train_p = '/content/drive/MyDrive/chest_xray/train/PNEUMONIA/'\n",
        "\n",
        "# Normal pic\n",
        "rand_norm = np.random.randint(0, len(os.listdir(train_n)))\n",
        "norm_pic = os.listdir(train_n)[rand_norm]\n",
        "norm_pic_address = train_n + norm_pic\n",
        "\n",
        "# Pneumonia pic\n",
        "rand_p = np.random.randint(0, len(os.listdir(train_p)))\n",
        "sic_pic = os.listdir(train_p)[rand_p]\n",
        "sic_address = train_p + sic_pic\n",
        "\n",
        "# Load the images and convert to grayscale\n",
        "norm_load = Image.open(norm_pic_address).convert('L')\n",
        "sic_load = Image.open(sic_address).convert('L')\n",
        "\n",
        "# Plot the images\n",
        "f = plt.figure(figsize=(10, 6))\n",
        "a1 = f.add_subplot(1, 2, 1)\n",
        "img_plot = plt.imshow(norm_load, cmap='gray')\n",
        "a1.set_title('Normal')\n",
        "\n",
        "a2 = f.add_subplot(1, 2, 2)\n",
        "img_plot = plt.imshow(sic_load, cmap='gray')\n",
        "a2.set_title('Pneumonia')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-hgVm9bizxkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 - Data pre-processing"
      ],
      "metadata": {
        "id": "PBknhGLiWijK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data is loaded and formatted to make sure it fits the CNN\n",
        "def random_rotation_angle():\n",
        "    return random.randint(0, 360)\n",
        "\n",
        "def load_images(path, label):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for img_path in glob.glob(path + '/*.jpeg'):\n",
        "        img = Image.open(img_path).convert('L').resize((64, 64))\n",
        "        rotation_angle = random_rotation_angle()\n",
        "        rotated_img = img.rotate(rotation_angle)\n",
        "        img_array = np.array(rotated_img) / 255.0\n",
        "        images.append(img_array)\n",
        "        labels.append(label)\n",
        "    return images, labels\n",
        "\n",
        "train_n = '/content/drive/MyDrive/chest_xray/train/NORMAL/'\n",
        "train_p = '/content/drive/MyDrive/chest_xray/train/PNEUMONIA/'\n",
        "\n",
        "normal_images, normal_labels = load_images(train_n, 0)\n",
        "pneumonia_images, pneumonia_labels = load_images(train_p, 1)\n",
        "\n",
        "images = normal_images + pneumonia_images\n",
        "labels = normal_labels + pneumonia_labels\n",
        "\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "images = images.reshape(-1, 64, 64, 1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "6UWDAS_X1RAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 - CNN model implementation using TensorFlow"
      ],
      "metadata": {
        "id": "FBbIl-yOWqHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN is developed for this problem in particular\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# First layer\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1), padding='same'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Dropout(0.25)) # Add dropout layer\n",
        "\n",
        "# Second layer\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Dropout(0.25)) # Add dropout layer\n",
        "\n",
        "# Third layer\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Dropout(0.25)) # Add dropout layer\n",
        "\n",
        "# Fourth layer\n",
        "model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Dropout(0.25)) # Add dropout layer\n",
        "\n",
        "# Flatten and add fully connected layers\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dropout(0.5)) # Add dropout layer\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dropout(0.5)) # Add dropout layer\n",
        "model.add(layers.Dense(2, activation='softmax'))\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "ghLf613L27mY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This callback function serves to end training if desired accuracy is reached\n",
        "'''\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy') >= 0.97):\n",
        "      print(\"\\nReached 97% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "'''"
      ],
      "metadata": {
        "id": "w1bjPvHu47dJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4 - Model training"
      ],
      "metadata": {
        "id": "-kOecqvmW1FC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We import the callback class to instantiate the callback function\n",
        "#callbacks = myCallback()\n",
        "\n",
        "# The model is compiled in order to start training\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy']\n",
        "              )\n",
        "# The data is fitted to the model and training starts\n",
        "history = model.fit(X_train, y_train, epochs=300, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "0YyKCj1X30og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.5 - Model results"
      ],
      "metadata": {
        "id": "Sl01iyk9W52A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot the model's loss and accuracy history to follow patterns that may be useful for insights\n",
        "def plot_history(history):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    \n",
        "    epochs = range(1, len(acc) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    \n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "    plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_history(history)"
      ],
      "metadata": {
        "id": "yUnm6Abp8kK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_acc, test_precision, test_recall, test_auc = model.evaluate(X_test, y_test, verbose=2)\n",
        "print(f'Test accuracy: {test_acc}')\n",
        "print(f'Test precision: {test_precision}')\n",
        "print(f'Test recall: {test_recall}')\n",
        "print(f'Test AUC: {test_auc}')"
      ],
      "metadata": {
        "id": "bJPanHdE7Wlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finally, we can make predictions with our model\n",
        "predictions = model.predict(X_test)\n",
        "predicted_labels = np.argmax(predictions, axis=1)"
      ],
      "metadata": {
        "id": "ri730F_r89aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This function plots the results graphically\n",
        "def display_predictions(images, true_labels, predicted_labels, num_images=10):\n",
        "    plt.figure(figsize=(num_images * 2, 3))\n",
        "\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(1, num_images, i + 1)\n",
        "        plt.imshow(images[i], cmap='gray')\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.xlabel(f'True: {true_labels[i]}\\nPred: {predicted_labels[i]}')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# We present the results by plotting them\n",
        "display_predictions(X_test, y_test, predicted_labels)"
      ],
      "metadata": {
        "id": "h6UeW35I9Zqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Conclusions**\n",
        "\n",
        "Based on the research conducted and the results obtained in the development of such a model, the research team has reached the following conclusions:\n",
        "\n",
        "* Pneumonia is a common and serious respiratory disease that can be difficult to diagnose accurately using traditional methods. The implemented neural network model shows high accuracy in classifying chest X-ray images, which could be a valuable tool to support the diagnosis of pneumonia.\n",
        "\n",
        "* The implementation of a neural network model for the detection of pneumonia in chest radiographs may help streamline the diagnostic process by reducing the need for clinicians to manually review each image. This could enable faster and more timely diagnosis, which is especially crucial in cases of severe pneumonia.\n",
        "\n",
        "* The use of deep learning techniques, such as a neural network model, can help overcome the limitations of traditional approaches to pneumonia diagnosis. By harnessing the power of artificial intelligence and machine learning, it is possible to detect subtle patterns in images that may be difficult to detect with the naked eye.\n",
        "\n",
        "* The high accuracy of the neural network model (with an accuracy of 93.12% as evaluated) indicates that the approach used is effective and promising for the detection of pneumonia in chest X-ray images. However, it is important to remember that no model is perfect and it is always necessary to consider limitations and possible classification errors.\n",
        "\n",
        "* The successful implementation of the neural network model demonstrates the potential of artificial intelligence in the medical field. Advances in this field can lead to significant improvements in the diagnosis and treatment of respiratory diseases, such as pneumonia, and potentially save lives.\n",
        "\n",
        "* To ensure reliability and safety in the clinical use of the neural network model, further validation using diversified and larger datasets is critical. This will help to assess the model's performance in different scenarios and populations, and to identify potential biases or limitations.\n",
        "\n",
        "* In addition to accuracy, it is also important to consider other aspects when implementing neural network models in clinical settings, such as model interpretability and transparency. Clinicians and healthcare professionals must be able to understand how decisions are made and trust the results provided by the model.\n",
        "\n",
        "* The neural network model implemented for the detection of pneumonia in chest X-ray images is a significant step toward the use of artificial intelligence in medicine. However, it is essential to remember that the technology must complement and support the expertise and clinical judgment of healthcare professionals, and not replace them.\n",
        "\n"
      ],
      "metadata": {
        "id": "E4WP2_ZTYIRD"
      }
    }
  ]
}